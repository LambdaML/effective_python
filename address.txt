2. If big text is passed to the `index_words` function is passed, it will eat all the memory available and 
probably crush, because of the results needs to be stored in the `list` and returned only after it 
finishes all the computations. 

Where in generator it only requires memory for a single loop instance. Thus it can iterate through very 
big files. Following version of the generator is adapted to work with on line from a file and yields 
output one words at a time:

```python
def index_file(handle):
    offset = 0
    for line in handle:
        if line:
            yield offset
        for letter in line:
            offset += 1
            if letter == ' ':
                yield offset

```
 